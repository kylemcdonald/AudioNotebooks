{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_root = 'data/drums/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from os.path import join\n",
    "from utils import *\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dense, Reshape, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time fingerprints = np.load(join(data_root, 'fingerprints.npy'))\n",
    "img_rows, img_cols = fingerprints.shape[1:]\n",
    "print fingerprints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(join(data_root, 'labels_to_samples.pkl'), 'rb') as f:\n",
    "    labels_to_samples = pickle.load(f)\n",
    "with open(join(data_root, 'samples_to_labels.pkl'), 'rb') as f:\n",
    "    samples_to_labels = pickle.load(f)\n",
    "synsets = json.load(open(join(data_root, 'synsets.json')))\n",
    "nb_classes = len(synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# take a sample of the data with even chunks for each class\n",
    "# the total number of samples can be larger than len(data) because some samples may be included under multiple labels\n",
    "# and the total can be less than limit_per_class * nb_classes because some classes might have less data\n",
    "def get_data(data, labels_to_samples, samples_to_labels, limit_per_class=100):\n",
    "    X_train = []\n",
    "    labels_train = []\n",
    "    for samples in labels_to_samples:\n",
    "        np.random.shuffle(samples)\n",
    "        for i in samples[:limit_per_class]:\n",
    "            X_train.append(data[i])\n",
    "            labels_train.append(samples_to_labels[i])\n",
    "    X_train = np.asarray(X_train)\n",
    "    nb_train = len(X_train)\n",
    "    nb_classes = len(labels_to_samples)\n",
    "    y_train = np.zeros((nb_train, nb_classes), dtype=np.float32)\n",
    "    for i, w in enumerate(labels_train):\n",
    "        y_train[i, w] = 1.\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_data(fingerprints, labels_to_samples, samples_to_labels)\n",
    "print(X_train.dtype, X_train.shape, X_train.min(), X_train.max())\n",
    "print(y_train.dtype, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(img_rows, img_cols))\n",
    "x = Reshape((1, img_rows, img_cols))(inputs)\n",
    "\n",
    "x = Convolution2D(32, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = Convolution2D(32, 3, 3, activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = Convolution2D(64, 3, 3, activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "encoded = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(encoded)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "classifier = Model(input=inputs, output=x)\n",
    "classifier.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "batch_size = 32\n",
    "nb_epoch = 10\n",
    "nb_slices = 48\n",
    "lr = 0.001\n",
    "decay = 0.99\n",
    "\n",
    "for d in range(nb_slices):\n",
    "    X_train, y_train = get_data(fingerprints, labels_to_samples, samples_to_labels)\n",
    "    print('Learning rate', lr)\n",
    "    K.set_value(classifier.optimizer.lr, lr)\n",
    "    classifier.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=nb_epoch,\n",
    "          verbose=1,\n",
    "          shuffle=True)\n",
    "    lr *= decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the network, it can be used later to predict labels for new sounds\n",
    "open(join(data_root, 'classifier.json'), 'w').write(classifier.to_json())\n",
    "classifier.save_weights(join(data_root, 'classifier.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make label predictions\n",
    "predicted_labels = classifier.predict(fingerprints)\n",
    "np.save(join(data_root, 'predicted_labels.npy'), predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make encoding predictions\n",
    "encoder = Model(input=inputs, output=encoded)\n",
    "encoder.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "predicted_encoding = encoder.predict(fingerprints)\n",
    "np.save(join(data_root, 'predicted_encoding.npy'), predicted_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show some examples of predicted encodings\n",
    "plt.figure(figsize=(30,2))\n",
    "plt.plot(predicted_encoding[:3].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show some examples of predicted labels\n",
    "# red lines indicate the real labels\n",
    "indices = np.arange(nb_classes)\n",
    "np.random.shuffle(indices)\n",
    "for i in indices[:10]:\n",
    "    cur = fingerprints[i].reshape(1,img_rows,img_cols)\n",
    "    cl = classifier.predict(cur, verbose=0)\n",
    "    plt.figure(figsize=(30,2))\n",
    "    for j in samples_to_labels[i]:\n",
    "        plt.axvline(j+.5,c='red')\n",
    "        print ', '.join(synsets[j])\n",
    "    plt.bar(np.arange(nb_classes), classifier.predict(cur, verbose=0)[0])\n",
    "    plt.xlim([0,nb_classes])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show at a mosaic of fingerprints for given synsets\n",
    "for label in [1,5,10]:\n",
    "    samples = labels_to_samples[label]\n",
    "    total = len(samples)\n",
    "    print ', '.join(synsets[label]), total\n",
    "    if total > 0:\n",
    "        show_array(255 * make_mosaic(fingerprints[samples]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
